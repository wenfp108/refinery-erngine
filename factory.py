import pandas as pd
import hashlib, json, os, requests, subprocess
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from supabase import create_client

class UniversalFactory:
    def __init__(self, masters_path="masters"):
        self.masters_path = Path(masters_path)
        self.masters = self._load_masters()
        self.api_key = os.environ.get("SILICON_FLOW_KEY")
        self.api_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.supabase_url = os.environ.get("SUPABASE_URL")
        self.supabase_key = os.environ.get("SUPABASE_KEY")
        self.vault_path = None
        
        # æ‰“å° Key çš„çŠ¶æ€ï¼ˆåªæ˜¾ç¤ºå‰å‡ ä½ï¼Œé˜²æ­¢æ³„éœ²ï¼‰
        if self.api_key:
            print(f"ğŸ”‘ API Key æ£€æµ‹: å·²åŠ è½½ (å‰ç¼€: {self.api_key[:4]}...)")
        else:
            print("âŒ ä¸¥é‡è­¦å‘Š: æœªæ£€æµ‹åˆ° SILICON_FLOW_KEYï¼API å°†æ— æ³•å·¥ä½œã€‚")

        self.v3_model = "deepseek-ai/DeepSeek-V3"
        self.free_model = "Qwen/Qwen2.5-7B-Instruct"

    def _load_masters(self):
        # ... (ä¿æŒåŸæ ·ï¼Œçœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼ŒåŠ è½½é€»è¾‘æ²¡é—®é¢˜) ...
        import importlib.util
        masters = {}
        if not self.masters_path.exists(): return masters
        for file_path in self.masters_path.glob("*.py"):
            if file_path.name.startswith("__"): continue
            try:
                name = file_path.stem
                spec = importlib.util.spec_from_file_location(name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                if hasattr(module, 'audit'): masters[name] = module
            except: pass
        return masters

    def configure_git(self):
        if not self.vault_path: return
        try:
            cwd = self.vault_path
            subprocess.run(["git", "config", "user.email", "bot@factory.com"], cwd=cwd, check=False)
            subprocess.run(["git", "config", "user.name", "Cognitive Bot"], cwd=cwd, check=False)
        except: pass

    def fetch_best_signals(self, limit=300):
        print(f"ğŸ“¡ å°è¯• SQL è·å–...")
        supabase = create_client(self.supabase_url, self.supabase_key)
        return supabase.table("raw_signals").select("*").order("created_at", desc=True).limit(limit).execute().data

    def call_ai(self, model, sys, usr):
        if not self.api_key: return "ERROR", "No API Key"
        payload = {
            "model": model, "messages": [{"role": "system", "content": sys}, {"role": "user", "content": usr}],
            "temperature": 0.7, "max_tokens": 1024
        }
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        try:
            res = requests.post(self.api_url, json=payload, headers=headers, timeout=45)
            if res.status_code == 200:
                return "SUCCESS", res.json()['choices'][0]['message']['content']
            else:
                # ğŸ”¥ å…³é”®ï¼šæ‰“å°å‡ºå…·ä½“çš„ API æŠ¥é”™ä¿¡æ¯
                print(f"âŒ API æŠ¥é”™ [{res.status_code}]: {res.text[:100]}")
                return "ERROR", f"API Fail: {res.status_code}"
        except Exception as e:
            print(f"âŒ ç½‘ç»œé”™è¯¯: {str(e)}")
            return "ERROR", "Timeout/NetError"

    def git_push_assets(self):
        if not self.vault_path: return
        try:
            cwd = self.vault_path
            subprocess.run(["git", "add", "."], cwd=cwd, check=True)
            if subprocess.run(["git", "diff", "--cached", "--quiet"], cwd=cwd).returncode != 0:
                print("ğŸ“¦ [Git] æ­£åœ¨æ¨é€...")
                subprocess.run(["git", "commit", "-m", f"ğŸ§  Batch: {datetime.now().strftime('%H:%M:%S')}"], cwd=cwd, check=True)
                subprocess.run(["git", "push"], cwd=cwd, check=True)
        except Exception as e: print(f"âš ï¸ Git Warning: {e}")

    def audit_process(self, row):
        # ğŸ”¥ 1. å¼ºåŠ›å†…å®¹æå– (æ ¹æ®ä½ çš„è°ƒè¯•æ—¥å¿—ä¼˜åŒ–)
        # å°† question å’Œ full_text æ‹¼èµ·æ¥ï¼Œé˜²æ­¢é—æ¼ä¿¡æ¯
        parts = []
        if row.get('title'): parts.append(str(row.get('title')))
        if row.get('question'): parts.append(str(row.get('question')))
        if row.get('full_text'): parts.append(str(row.get('full_text')))
        
        content = "\n".join(parts)
        if len(content) < 5: return [] # çœŸçš„æ²¡å†…å®¹æ‰è·³è¿‡

        ref_id = hashlib.sha256(content.encode()).hexdigest()
        title = content[:50].replace('\n', ' ')

        # ğŸ”¥ 2. å…è´¹æ‰“åˆ†
        _, score_reply = self.call_ai(self.free_model, "ç»™æ­¤ä¿¡æ¯ä»·å€¼æ‰“åˆ†(0-100)ã€‚åªå›æ•°å­—ã€‚", content[:800])
        try: score = int(''.join(filter(str.isdigit, score_reply)))
        except: score = 0 # å¦‚æœ API æŒ‚äº†ï¼Œé»˜è®¤ä¸º 0

        results = []

        # ğŸ¯ 3. åˆ†æµé€»è¾‘
        # æƒ…å†µ A: é¡¶çº§ä¿¡å· (V3)
        if score > 80:
            def ask_v3(s, u):
                st, r = self.call_ai(self.v3_model, s, u)
                if st == "SUCCESS" and "### Output" in r:
                    return r.split("### Output")[0].replace("### Thought","").strip(), r.split("### Output")[1].strip()
                return "åˆ†æ", r
            for name, mod in self.masters.items():
                try:
                    t, o = mod.audit(row, ask_v3)
                    if t and o: results.append(json.dumps({"ref_id":ref_id, "type":"V3_MASTER", "master":name, "input":title, "thought":t, "output":o}, ensure_ascii=False))
                except: continue

        # æƒ…å†µ B: æ™®é€šä¿¡å· (å…è´¹æ¨¡å‹) - åªè¦ API æ´»ç€å°±è·‘
        elif score > 0: 
            st, r = self.call_ai(self.free_model, "ä¸€å¥è¯æ€»ç»“æ ¸å¿ƒä»·å€¼", content[:800])
            if st == "SUCCESS":
                results.append(json.dumps({"ref_id":ref_id, "type":"FREE_SCAN", "master":"system", "input":title, "output":r}, ensure_ascii=False))
        
        # æƒ…å†µ C: API å…¨æŒ‚äº† (ä¿åº•æªæ–½) - å­˜åŸå§‹æ•°æ®ï¼Œè¯æ˜æµç¨‹é€šäº†
        else:
            # è¿™æ˜¯ä¸€ä¸ªâ€œæ­»ä¿¡â€ï¼Œè™½ç„¶æ²¡ AI åˆ†æï¼Œä½†è‡³å°‘è®©ä½ çŸ¥é“æ•°æ®æµåˆ°äº†è¿™é‡Œ
            results.append(json.dumps({"ref_id":ref_id, "type":"RAW_BACKUP", "master":"backup", "input":title, "error": "API_FAILED_OR_TRASH"}, ensure_ascii=False))

        return results

    def process_and_ship(self, input_raw, vault_path):
        self.vault_path = Path(vault_path)
        self.configure_git()
        
        signals = []
        try:
            signals = self.fetch_best_signals(limit=300)
            print(f"âœ… SQL è·å– {len(signals)} æ¡ã€‚")
        except:
            print(f"ğŸ”„ é™çº§è¯»å–æœ¬åœ°æ–‡ä»¶...")
            try:
                # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ–‡ä»¶é‡Œæ··äº†é dict æ ¼å¼
                df = pd.read_parquet(input_raw)
                signals = df.head(300).to_dict('records')
            except: 
                print("âŒ æ— æ³•è¯»å–æ•°æ®æº"); return

        day_str = datetime.now().strftime('%Y%m%d')
        output_file = self.vault_path / "instructions" / f"teachings_{day_str}.jsonl"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        # ğŸ“‰ é™é€Ÿï¼šå¹¶å‘é™åˆ° 5ï¼Œé˜²æ­¢ç¬é—´æŠŠå…è´¹ API æ‰“æŒ‚
        print(f"ğŸš€ å·¥å‚å¼€å·¥ï¼å¤„ç† {len(signals)} æ¡æ•°æ® (å¹¶å‘: 5)...")
        
        for i in range(0, len(signals), 50):
            batch = signals[i : i + 50]
            with ThreadPoolExecutor(max_workers=5) as executor:
                res = list(executor.map(self.audit_process, batch))
            
            added = 0
            with open(output_file, 'a', encoding='utf-8') as f:
                for r_list in res:
                    if r_list:
                        f.write('\n'.join(r_list) + '\n')
                        added += 1
            
            print(f"âœ¨ è¿›åº¦ {i+len(batch)}/{len(signals)} | æœ¬æ‰¹å…¥åº“: {added} æ¡")
            if added > 0: self.git_push_assets()

        print("ğŸ ä»»åŠ¡ç»“æŸã€‚")
