import pandas as pd
import hashlib
import json
import os
import importlib.util
import sys
from pathlib import Path

class UniversalFactory:
    def __init__(self, masters_path="masters"):
        # ä½¿ç”¨ Path å¯¹è±¡ï¼Œå¤„ç†è·¯å¾„æ›´å®‰å…¨
        self.masters_path = Path(masters_path)
        self.masters = self._load_masters()

    def _load_masters(self):
        masters = {}
        if not self.masters_path.exists():
            print(f"âš ï¸ [è­¦å‘Š] å¤§å¸ˆç›®å½•ä¸å­˜åœ¨: {self.masters_path}")
            return masters

        # éå† .py æ–‡ä»¶
        for file_path in self.masters_path.glob("*.py"):
            if file_path.name.startswith("__"): continue
            
            try:
                name = file_path.stem # è·å–æ–‡ä»¶åï¼ˆæ— åç¼€ï¼‰
                spec = importlib.util.spec_from_file_location(name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ audit å‡½æ•°ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆæ’ä»¶
                if hasattr(module, 'audit'):
                    masters[name] = module
                    print(f"âœ… [åŠ è½½æˆåŠŸ] è®¤çŸ¥æ’ä»¶: {name}")
                else:
                    print(f"âš ï¸ [è·³è¿‡] {name} ç¼ºå°‘ audit() å‡½æ•°")
            except Exception as e:
                print(f"âŒ [åŠ è½½å¤±è´¥] {file_path.name}: {e}")
        
        return masters

    def generate_ref_id(self, row_dict):
        """ç”Ÿæˆæ°¸ä¹…å“ˆå¸Œ ID (å¢å¼ºé€šç”¨æ€§)"""
        # ä¼˜å…ˆä½¿ç”¨ Polymarket ç‰¹å¾
        p1 = str(row_dict.get('eventTitle') or '')
        p2 = str(row_dict.get('question') or '')
        content = f"{p1}{p2}"
        
        # ğŸ›¡ï¸ é€šç”¨å…œåº•ï¼šå¦‚æœä¸æ˜¯ Polymarket æ•°æ®ï¼Œåˆ™ä½¿ç”¨æ•´è¡Œæ•°æ®çš„å“ˆå¸Œ
        if not p1 and not p2:
            # sort_keysç¡®ä¿å­—å…¸é¡ºåºä¸€è‡´ï¼Œä¿è¯å“ˆå¸Œå”¯ä¸€æ€§
            content = json.dumps(row_dict, sort_keys=True, default=str)
            
        return hashlib.sha256(content.encode()).hexdigest()

    def process_and_ship(self, input_raw, vault_path, batch_size=2000):
        """åŠ å·¥å¹¶é€å›ä¸­å¤®é“¶è¡Œ (æµå¼å†™å…¥ç‰ˆ)"""
        input_path = Path(input_raw)
        vault_dir = Path(vault_path)
        
        if not input_path.exists():
            print(f"âŒ [é”™è¯¯] æ‰¾ä¸åˆ°åŸå§‹å½’æ¡£: {input_path}")
            return

        # 1. è¯»å–æ•°æ®
        try:
            df = pd.read_parquet(input_path)
            print(f"ğŸ­ å·¥å‚å¯åŠ¨: æ­£åœ¨å¤„ç† {len(df)} æ¡åŸå§‹ä¿¡å·ï¼Œè°ƒç”¨ {len(self.masters)} ä½å¤§å¸ˆ...")
        except Exception as e:
            print(f"âŒ Parquet è¯»å–å¤±è´¥: {e}")
            return

        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶ (è‡ªåŠ¨åˆ›å»ºçˆ¶æ–‡ä»¶å¤¹)
        output_file = vault_dir / "instructions" / "teachings.jsonl"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        buffer = []
        count = 0
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–: to_dict('records') æ¯” iterrows å¿«å‡ åå€
        rows = df.to_dict('records')

        # ä½¿ç”¨ append æ¨¡å¼æ‰“å¼€ï¼Œæ”¯æŒæ–­ç‚¹ç»­å†™
        with open(output_file, 'a', encoding='utf-8') as f:
            for row_dict in rows:
                ref_id = self.generate_ref_id(row_dict)
                event_title = row_dict.get('eventTitle', 'æœªå‘½åäº‹ä»¶')

                # å¹¶è¡Œå®¡è®¡ (é€»è¾‘å±‚é¢)
                for master_name, master_mod in self.masters.items():
                    try:
                        # è·å–ç‰ˆæœ¬å·ï¼Œé»˜è®¤ä¸º 1.0
                        ver = getattr(master_mod, "VERSION", "1.0")
                        
                        # ğŸ›¡ï¸ ç†”æ–­ä¿æŠ¤ï¼šé˜²æ­¢å•ä¸ªå¤§å¸ˆæŠ¥é”™å¡æ­»æ•´ä¸ªæµç¨‹
                        thought, output = master_mod.audit(row_dict)

                        entry = {
                            "ref_id": ref_id,
                            "master": master_name,
                            "version": ver,
                            "instruction": f"è¯·åˆ†æäº‹ä»¶: {event_title}",
                            "thought": thought,
                            "output": output
                        }
                        buffer.append(json.dumps(entry, ensure_ascii=False))
                        
                    except Exception as e:
                        # ä»…æ‰“å°é”™è¯¯ï¼Œä¸ä¸­æ–­å¾ªç¯
                        # print(f"âš ï¸ [{master_name}] å®¡è®¡å¤±è´¥: {e}") 
                        pass

                # ğŸš€ å†…å­˜ä¿æŠ¤: ç§¯æ”’åˆ° batch_size å†å†™å…¥ç¡¬ç›˜
                if len(buffer) >= batch_size:
                    f.write('\n'.join(buffer) + '\n')
                    count += len(buffer)
                    buffer = [] # æ¸…ç©ºç¼“å†²åŒº
            
            # å†™å…¥å‰©ä½™æ•°æ®
            if buffer:
                f.write('\n'.join(buffer) + '\n')
                count += len(buffer)

        print(f"ğŸš€ [å‘è´§å®Œæˆ] å·²å°† {count} æ¡è®¤çŸ¥èµ„äº§æ³¨å…¥ä¸­å¤®é“¶è¡Œ: {output_file}")

if __name__ == "__main__":
    # ç¤ºä¾‹è°ƒç”¨
    # å‡è®¾æ­¤æ—¶åœ¨ refinery-engine æ ¹ç›®å½•
    factory = UniversalFactory(masters_path="../Masters-Council/masters")
    factory.process_and_ship(
        input_raw="temp_raw.parquet", 
        vault_path="../Central-Bank"
    )
