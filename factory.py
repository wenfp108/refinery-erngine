import pandas as pd
import hashlib, json, os, requests, importlib.util, subprocess, time
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from supabase import create_client

class UniversalFactory:
    def __init__(self, masters_path="masters"):
        self.masters_path = Path(masters_path)
        self.masters = self._load_masters()
        # API é…ç½®
        self.api_key = os.environ.get("SILICON_FLOW_KEY")
        self.api_url = "https://api.siliconflow.cn/v1/chat/completions"
        # SQL é…ç½®
        self.supabase_url = os.environ.get("SUPABASE_URL")
        self.supabase_key = os.environ.get("SUPABASE_KEY")
        self.vault_path = None
        
        # æ€§èƒ½ä¸è®¡è´¹æ§åˆ¶
        self.v3_model = "deepseek-ai/DeepSeek-V3"
        self.free_model = "Qwen/Qwen2.5-7B-Instruct" # å…è´¹ç‰ˆ

    def _load_masters(self):
        masters = {}
        if not self.masters_path.exists(): return masters
        for file_path in self.masters_path.glob("*.py"):
            if file_path.name.startswith("__"): continue
            try:
                name = file_path.stem
                spec = importlib.util.spec_from_file_location(name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                if hasattr(module, 'audit'): masters[name] = module
            except: pass
        return masters

    def fetch_best_signals(self, limit=300):
        """ä» SQL ä¸­æŒ‘é€‰æœ€ä¼˜è´¨çš„ 300 æ¡æ•°æ®ï¼Œä¸å†æ— è„‘å¤„ç† 1000 æ¡"""
        print(f"ğŸ“¡ æ­£åœ¨ä»ä¸­å¤®é“¶è¡Œ SQL ç­›é€‰å‰ {limit} æ¡é«˜ä»·å€¼ä¿¡å·...")
        supabase = create_client(self.supabase_url, self.supabase_key)
        # é€»è¾‘ï¼šæŒ‰æ—¶é—´å€’åºï¼Œæˆ–è€…ä½ å¯ä»¥æ”¹ä¸ºæŒ‰çƒ­åº¦/ç‚¹èµæ•°æ’åº
        response = supabase.table("raw_signals").select("*").order("created_at", desc=True).limit(limit).execute()
        return response.data

    def call_ai(self, model, sys, usr, temp=0.7):
        if not self.api_key: return "ERROR", "Missing Key"
        payload = {
            "model": model, "messages": [{"role": "system", "content": sys}, {"role": "user", "content": usr}],
            "temperature": temp, "max_tokens": 1024
        }
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        try:
            res = requests.post(self.api_url, json=payload, headers=headers, timeout=45).json()
            return "SUCCESS", res['choices'][0]['message']['content']
        except: return "ERROR", "Timeout"

    def git_push_assets(self):
        """æ¯50æ¡å¼ºåˆ¶æŠ¼è¿ä¸€æ¬¡"""
        if not self.vault_path: return
        try:
            cwd = self.vault_path
            subprocess.run(["git", "add", "."], cwd=cwd, check=True)
            status = subprocess.run(["git", "diff", "--cached", "--quiet"], cwd=cwd)
            if status.returncode != 0:
                print("ğŸ“¦ [æŠ¼è¿ä¸­] 50æ¡èµ„äº§å·²æ‰“åŒ…ï¼Œæ­£åœ¨åŒæ­¥è‡³äº‘ç«¯ä»“åº“...")
                subprocess.run(["git", "commit", "-m", f"ğŸ§  Batch Sync: {datetime.now().strftime('%H:%M:%S')}"], cwd=cwd, check=True)
                subprocess.run(["git", "push"], cwd=cwd, check=True)
                print("âœ… [åŒæ­¥æˆåŠŸ] äº‘ç«¯å·²æ›´æ–°ã€‚")
        except Exception as e: print(f"âš ï¸ Gitæ¨é€å¤±è´¥: {e}")

    def audit_process(self, row):
        """æ™ºèƒ½æ¼æ–—å®¡è®¡é€»è¾‘ï¼šç²¾åç”¨ V3ï¼Œæ™®é€šèµ°å…è´¹"""
        content = str(row.get('full_text') or row.get('eventTitle') or '')
        ref_id = hashlib.sha256(content.encode()).hexdigest()
        
        # 1. è¯„åˆ†åˆç­› (Scout) - ä½¿ç”¨å…è´¹æ¨¡å‹
        scout_sys = "ä½ æ˜¯ä¸€ä¸ªé«˜ä»·å€¼ä¿¡æ¯ç­›é€‰å™¨ã€‚ç»™ä»¥ä¸‹å†…å®¹æ‰“åˆ†(0-100)ã€‚æ¶‰åŠå®è§‚ç»æµã€æŠ€æœ¯è½¬æŠ˜æˆ–æ·±åº¦å“²å­¦çš„å†…å®¹æ‰“é«˜åˆ†ã€‚åªå›ç­”æ•°å­—ã€‚"
        _, score_reply = self.call_ai(self.free_model, scout_sys, content[:600], temp=0.1)
        
        try: score = int(''.join(filter(str.isdigit, score_reply)))
        except: score = 50

        results = []
        title = content[:50]
        
        # ğŸ¯ æ ¸å¿ƒé€»è¾‘ï¼šåªæœ‰å¤§äº 80 åˆ†çš„æ‰è¯·â€œå¤§å¸ˆè®®ä¼šâ€ç”¨é¡¶çº§ V3
        if score > 80:
            def ask_v3(s, u):
                st, r = self.call_ai(self.v3_model, s, u)
                if st == "SUCCESS" and "### Output" in r:
                    return r.split("### Output")[0].replace("### Thought","").strip(), r.split("### Output")[1].strip()
                return "æ·±åº¦åˆ†æ", r
            
            for name, mod in self.masters.items():
                try:
                    t, o = mod.audit(row, ask_v3)
                    if t and o: results.append(json.dumps({"ref_id":ref_id, "master":name, "instruction":f"ç ”åˆ¤: {title}", "thought":t, "output":o}, ensure_ascii=False))
                except: continue
        
        # ğŸ¯ å¤‡é€‰é€»è¾‘ï¼š50-80 åˆ†çš„ï¼Œåªè¯·ä¸€ä½è½®å€¼å¤§å¸ˆç”¨å…è´¹æ¨¡å‹å¤„ç†
        elif score > 50:
            st, r = self.call_ai(self.free_model, "è¯·ç®€è¦åˆ†ææ­¤ä¿¡æ¯ä»·å€¼", content[:500])
            results.append(json.dumps({"ref_id":ref_id, "master":"system", "instruction":f"ç®€è¯„: {title}", "thought":"å¿«é€Ÿæ‰«æ", "output":r}, ensure_ascii=False))

        return results

    def process_and_ship(self, _, vault_path):
        """ä¸»å…¥å£ï¼šå¿½ç•¥æœ¬åœ°inputï¼Œç›´æ¥SQLå–æ•°"""
        self.vault_path = Path(vault_path)
        signals = self.fetch_best_signals(limit=300) # âœ… åªå–300æ¡
        
        day_str = datetime.now().strftime('%Y%m%d')
        output_file = self.vault_path / "instructions" / f"teachings_{day_str}.jsonl"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        batch_size = 50
        print(f"ğŸš€ å·¥å‚å¼€å·¥ï¼ç›®æ ‡ï¼š300 æ¡ä¼˜è´¨ä¿¡å·ï¼Œæ‰¹æ¬¡å¤§å°ï¼š{batch_size}")

        for i in range(0, len(signals), batch_size):
            batch_rows = signals[i : i + batch_size]
            
            # ğŸš€ å¹¶å‘æå‡ï¼šåˆ©ç”¨ 10 ä¸ªå¹¶å‘çª—å£åŠ é€Ÿï¼Œç¡®ä¿ 30 åˆ†é’Ÿå†…è·‘å®Œ
            with ThreadPoolExecutor(max_workers=10) as executor:
                batch_results = list(executor.map(self.audit_process, batch_rows))
            
            # å†™å…¥ç£ç›˜
            written_count = 0
            with open(output_file, 'a', encoding='utf-8') as f:
                for res_list in batch_results:
                    if res_list:
                        f.write('\n'.join(res_list) + '\n')
                        written_count += 1
            
            print(f"âœ¨ å·²å¤„ç†ä¸€æ‰¹ ({i+batch_size}/300)ã€‚æœ¬æ‰¹æ¬¡äº§å‡º {written_count} æ¡ã€‚")
            self.git_push_assets() # âœ… 50æ¡ä¸€æŠ¼è¿

        print("ğŸ ä»»åŠ¡åœ†æ»¡å®Œæˆã€‚")
