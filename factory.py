import pandas as pd
import hashlib, json, os, requests, importlib.util, subprocess, time
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from supabase import create_client

class UniversalFactory:
    def __init__(self, masters_path="masters"):
        self.masters_path = Path(masters_path)
        self.masters = self._load_masters()
        # ç¯å¢ƒå˜é‡
        self.api_key = os.environ.get("SILICON_FLOW_KEY")
        self.api_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.supabase_url = os.environ.get("SUPABASE_URL")
        self.supabase_key = os.environ.get("SUPABASE_KEY")
        self.vault_path = None
        
        # æ¨¡å‹é…ç½®
        self.v3_model = "deepseek-ai/DeepSeek-V3"
        self.free_model = "Qwen/Qwen2.5-7B-Instruct"

    def _load_masters(self):
        masters = {}
        if not self.masters_path.exists(): return masters
        for file_path in self.masters_path.glob("*.py"):
            if file_path.name.startswith("__"): continue
            try:
                name = file_path.stem
                spec = importlib.util.spec_from_file_location(name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                if hasattr(module, 'audit'): masters[name] = module
            except: pass
        return masters

    def fetch_best_signals(self, limit=300):
        """æ ¸å¿ƒï¼šä» SQL æŠ“å–æœ€è¿‘ 1 å°æ—¶çš„é«˜ä»·å€¼ä¿¡å·"""
        print(f"ğŸ“¡ æ­£åœ¨ä» SQL ç­›é€‰æœ€è¿‘ {limit} æ¡é«˜ä»·å€¼ä¿¡å·...")
        supabase = create_client(self.supabase_url, self.supabase_key)
        # ä¼˜å…ˆé€‰æ‹©å­—æ•°ä¸°å¯Œä¸”æœ€æ–°çš„ä¿¡å·
        response = supabase.table("raw_signals") \
            .select("*") \
            .order("created_at", desc=True) \
            .limit(limit) \
            .execute()
        return response.data

    def call_ai(self, model, sys, usr):
        if not self.api_key: return "ERROR", "Missing Key"
        payload = {
            "model": model, "messages": [{"role": "system", "content": sys}, {"role": "user", "content": usr}],
            "temperature": 0.7, "max_tokens": 1024
        }
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        try:
            res = requests.post(self.api_url, json=payload, headers=headers, timeout=45).json()
            return "SUCCESS", res['choices'][0]['message']['content']
        except: return "ERROR", "Timeout"

    def git_push_assets(self):
        """ã€æ•‘å‘½é€»è¾‘ã€‘æ¯50æ¡å¼ºåˆ¶åŒæ­¥ä¸€æ¬¡ï¼Œé˜²æ­¢ä¸­é€”æ–­å¼€é’±ç™½èŠ±"""
        if not self.vault_path: return
        try:
            cwd = self.vault_path
            subprocess.run(["git", "add", "."], cwd=cwd, check=True)
            status = subprocess.run(["git", "diff", "--cached", "--quiet"], cwd=cwd)
            if status.returncode != 0:
                print("ğŸ“¦ [åˆ†æ‰¹åŒæ­¥] 50æ¡å®¡è®¡èµ„äº§å·²æ‰“åŒ…ï¼Œæ­£åœ¨æŠ¼è¿è‡³ä¸­å¤®é“¶è¡Œ...")
                subprocess.run(["git", "commit", "-m", f"ğŸ§  Batch Update: {datetime.now().strftime('%H:%M:%S')}"], cwd=cwd, check=True)
                subprocess.run(["git", "push"], cwd=cwd, check=True)
                print("âœ… [æŠ¼è¿æˆåŠŸ] èµ„äº§å·²é”å®šã€‚")
        except Exception as e: print(f"âš ï¸ GitåŒæ­¥å¤±è´¥: {e}")

    def audit_process(self, row):
        """æ™ºèƒ½æ¼æ–—ï¼šç²¾åèµ° V3ï¼Œæ™®é€šèµ°å…è´¹"""
        content = str(row.get('full_text') or row.get('eventTitle') or '')
        ref_id = hashlib.sha256(content.encode()).hexdigest()
        
        # 1. å…è´¹æ‰“åˆ†
        scout_sys = "ä½ æ˜¯ä¸€ä¸ªé«˜ä»·å€¼ä¿¡æ¯ç­›é€‰å™¨ã€‚ç»™ä»¥ä¸‹å†…å®¹æ‰“åˆ†(0-100)ã€‚åªå›ç­”æ•°å­—ã€‚"
        _, score_reply = self.call_ai(self.free_model, scout_sys, content[:500])
        
        try: score = int(''.join(filter(str.isdigit, score_reply)))
        except: score = 50

        results = []
        title = content[:50]
        
        # ç²¾åä¿¡å·ï¼šå…¨é‡å¤§å¸ˆå®¡è®¡ (DeepSeek-V3)
        if score > 80:
            def ask_v3(s, u):
                st, r = self.call_ai(self.v3_model, s, u)
                if st == "SUCCESS" and "### Output" in r:
                    return r.split("### Output")[0].replace("### Thought","").strip(), r.split("### Output")[1].strip()
                return "ç»¼åˆç ”åˆ¤", r
            
            for name, mod in self.masters.items():
                try:
                    t, o = mod.audit(row, ask_v3)
                    if t and o: results.append(json.dumps({"ref_id":ref_id, "master":name, "instruction":f"ç ”åˆ¤: {title}", "thought":t, "output":o}, ensure_ascii=False))
                except: continue
        
        # æ™®é€šä¿¡å·ï¼šå•äººå¿«é€Ÿç®€è¯„ (Qwen-7B)
        elif score > 50:
            st, r = self.call_ai(self.free_model, "è¯·ç”¨ä¸€å¥è¯æå–è¯¥ä¿¡æ¯çš„å…³é”®ä»·å€¼ç‚¹", content[:500])
            if st == "SUCCESS":
                results.append(json.dumps({"ref_id":ref_id, "master":"system", "instruction":f"å¿«è¯„: {title}", "thought":"å¿«é€Ÿæ‰«æ", "output":r}, ensure_ascii=False))

        return results

    def process_and_ship(self, input_raw, vault_path): # âœ… ä¿®å¤ç­¾åï¼Œå…¼å®¹ run_factory.py
        self.vault_path = Path(vault_path)
        # æ ¸å¿ƒæ”¹å˜ï¼šä¸å†å¤„ç† input_raw é‡Œçš„ 1000 æ¡ï¼Œç›´æ¥ SQL æ‹¿ 300 æ¡
        signals = self.fetch_best_signals(limit=300) 
        
        day_str = datetime.now().strftime('%Y%m%d')
        output_file = self.vault_path / "instructions" / f"teachings_{day_str}.jsonl"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        batch_size = 50
        print(f"ğŸš€ å·¥å‚å¼€å·¥ï¼æ¯ {batch_size} æ¡å®¡è®¡è‡ªåŠ¨ä¿å­˜ã€‚")

        for i in range(0, len(signals), batch_size):
            batch_rows = signals[i : i + batch_size]
            
            # ä½¿ç”¨ 10 å¹¶å‘ï¼Œç¡®ä¿ 15-20 åˆ†é’Ÿå†…è·‘å®Œ 300 æ¡
            with ThreadPoolExecutor(max_workers=10) as executor:
                batch_results = list(executor.map(self.audit_process, batch_rows))
            
            # æ‰¹é‡å†™å…¥
            batch_added = 0
            with open(output_file, 'a', encoding='utf-8') as f:
                for res_list in batch_results:
                    if res_list:
                        f.write('\n'.join(res_list) + '\n')
                        batch_added += 1
            
            print(f"âœ¨ è¿›åº¦: {i+len(batch_rows)}/300ã€‚æœ¬æ‰¹æ¬¡äº§å‡º {batch_added} æ¡è§è§£ã€‚")
            self.git_push_assets() # âœ… å®æ—¶åŒæ­¥è¿›åº¦

        print("ğŸ å…¨é‡ 300 æ¡ä»»åŠ¡å·²æ”¶å·¥ã€‚")
