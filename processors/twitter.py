import json
import math
from datetime import datetime, timedelta

# === âš™ï¸ 1. åŸºç¡€é…ç½® ===
TABLE_NAME = "twitter_logs"
ARCHIVE_FOLDER = "twitter"

# âš ï¸ æ³¨æ„ï¼šè¿™ä¸ªåˆ—è¡¨çš„é¡ºåºå†³å®šäº†å½’ç±»çš„ä¼˜å…ˆçº§
# ä¾‹å¦‚ï¼šä¸€æ¡æ¨æ–‡åŒæ—¶æœ‰ Politics å’Œ Techï¼Œå®ƒä¼šä¼˜å…ˆè¿›å…¥ Politics æ¿å—
SECTORS = ["Politics", "Geopolitics", "Science", "Tech", "Finance", "Crypto", "Economy"]
TARGET_TOTAL_QUOTA = 30 

# === ğŸ› ï¸ 2. æ•°æ®æ¸…æ´— (å…¥åº“) ===
def fmt_k(num):
    if not num: return "-"
    try: n = float(num)
    except: return "-"
    if n >= 1_000_000: return f"{n/1_000_000:.1f}M"
    if n >= 1_000: return f"{n/1_000:.1f}K"
    return str(int(n))

def to_iso_bj(date_str):
    try:
        utc_dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S +0000 %Y')
        return (utc_dt + timedelta(hours=8)).isoformat()
    except:
        return datetime.now().isoformat()

def process(raw_data, path):
    items = raw_data if isinstance(raw_data, list) else [raw_data]
    refined_results = []
    
    for i in items:
        user = i.get('user', {})
        metrics = i.get('metrics', {})
        growth = i.get('growth', {})
        
        row = {
            "bj_time": to_iso_bj(i.get('createdAt')),
            "user_name": user.get('name'),
            "screen_name": user.get('screenName'),
            "followers_count": user.get('followersCount'),
            "full_text": i.get('fullText'),
            "url": i.get('tweetUrl'), 
            "tags": i.get('tags', []),
            
            # åŸºç¡€æ•°æ®
            "likes": metrics.get('likes', 0),
            "retweets": metrics.get('retweets', 0),
            "replies": metrics.get('replies', 0),
            "quotes": metrics.get('quotes', 0),
            "bookmarks": metrics.get('bookmarks', 0),
            "views": metrics.get('views', 0),
            
            # å¢é•¿æ•°æ®
            "growth_views": growth.get('views', 0),
            "growth_likes": growth.get('likes', 0),
            "growth_retweets": growth.get('retweets', 0),
            "growth_replies": growth.get('replies', 0),
            
            "raw_json": i 
        }
        refined_results.append(row)
    return refined_results

# === ğŸ§® 3. æ ¸å¿ƒæ‰“åˆ†å…¬å¼ ===
def calculate_twitter_score(item):
    base_interaction = (
        item.get('retweets', 0) * 8 + 
        item.get('quotes', 0) * 12 + 
        item.get('replies', 0) * 5 + 
        item.get('bookmarks', 0) * 10
    )
    
    growth_momentum = (
        item.get('growth_likes', 0) * 15 + 
        item.get('growth_retweets', 0) * 25 + 
        item.get('growth_replies', 0) * 10
    )
    
    synergy_boost = 1 + (len(item.get('tags', [])) * 0.3)
    
    return (base_interaction + growth_momentum) * synergy_boost

# === ğŸ“¤ 4. æˆ˜æŠ¥ç”Ÿæˆ (å«å»é‡ + ç‹¬å é€»è¾‘) ===
def get_hot_items(supabase, table_name):
    # 1. æ‹‰å–è¿‡å» 24 å°æ—¶å…¨é‡æ•°æ®
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_tweets = res.data if res.data else []
    except Exception as e:
        return {}

    if not all_tweets: return {}

    # 2. é¢„è®¡ç®—åˆ†æ•°
    for t in all_tweets:
        t['_score'] = calculate_twitter_score(t)

    # 3. URL å»é‡ (ä¿ç•™åˆ†æ•°æœ€é«˜çš„ç‰ˆæœ¬)
    unique_map = {}
    for t in all_tweets:
        key = t.get('url') or (t.get('user_name'), t.get('full_text'))
        if key not in unique_map:
            unique_map[key] = t
        else:
            if t['_score'] > unique_map[key]['_score']:
                unique_map[key] = t
    
    deduplicated_tweets = list(unique_map.values())
    total_unique_tweets = len(deduplicated_tweets)

    # ğŸ”¥ğŸ”¥ 4. ç‹¬å å¼åˆ†é… (æ ¸å¿ƒä¿®æ”¹ç‚¹) ğŸ”¥ğŸ”¥
    sector_pools = {s: [] for s in SECTORS}
    
    for t in deduplicated_tweets:
        tags = t.get('tags', [])
        
        # æŒ‰ç…§ SECTORS åˆ—è¡¨çš„é¡ºåºè¿›è¡ŒåŒ¹é…
        # ä¼˜å…ˆçº§é«˜çš„æ¿å— (å¦‚ Politics) ä¼šå…ˆæŠ¢èµ°æ¨æ–‡
        matched = False
        for sector in SECTORS:
            if sector in tags:
                sector_pools[sector].append(t)
                matched = True
                break # <--- ğŸ›‘ å…³é”®ï¼šæ‰¾åˆ°å½’å®¿åç«‹å³åœæ­¢ï¼Œé˜²æ­¢ä¸€ç¨¿å¤šæŠ•ï¼
        
        # (å¯é€‰) å¦‚æœæ²¡åŒ¹é…åˆ°ä»»ä½•æ¿å—ï¼Œå¯ä»¥æ”¾å…¥ Otherï¼Œè¿™é‡Œæš‚ä¸å¤„ç†

    # 5. ç”Ÿæˆæœ€ç»ˆçŸ©é˜µ (é€‚é… 6 åˆ—å¸ƒå±€)
    intelligence_matrix = {}
    
    for sector, pool in sector_pools.items():
        if not pool: continue
        
        # æ’åº
        pool.sort(key=lambda x: x['_score'], reverse=True)
        
        # é…é¢
        quota = max(3, math.ceil((len(pool) / total_unique_tweets) * TARGET_TOTAL_QUOTA))
        
        display_items = []
        for t in pool[:quota]:
            score = fmt_k(t['_score'])
            views = fmt_k(t.get('views', 0))
            user = t['user_name']
            text = t['full_text'].replace('\n', ' ')[:85] + "..." # ç¨å¾®åŠ é•¿æ‘˜è¦
            url = t['url']
            
            # ç»„è£…é€‚é… Refinery çš„æ•°æ®
            display_items.append({
                "display_score": score,
                "display_heat": f"ğŸ‘ï¸ {views}", # å¯¹åº” èµ„é‡‘/çƒ­åº¦
                "display_source": user,        # å¯¹åº” çŠ¶æ€/æºå¤´
                "display_tags": "",            # Twitter ä¸éœ€è¦é¢å¤–æ ‡ç­¾åˆ—
                "display_summary": text,       # å¯¹åº” æ‘˜è¦
                "url": url
            })
        
        intelligence_matrix[sector] = display_items

    return intelligence_matrix
