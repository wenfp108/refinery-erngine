import json
import math
from datetime import datetime, timedelta

TABLE_NAME = "polymarket_logs"
RADAR_TARGET_TOTAL = 50  

# ğŸ¨ ç¾åŒ–å·¥å…·
def fmt_k(num, prefix=""):
    if not num: return "-"
    try: n = float(num)
    except: return "-"
    if n >= 1_000_000_000_000: return f"{prefix}{n/1_000_000_000_000:.1f}T"
    if n >= 1_000_000_000: return f"{prefix}{n/1_000_000_000:.1f}B"
    if n >= 1_000_000: return f"{prefix}{n/1_000_000:.1f}M"
    if n >= 1_000: return f"{prefix}{n/1_000:.1f}K"
    return f"{prefix}{int(n)}"

def to_bj_time(utc_str):
    if not utc_str: return None
    try:
        dt = datetime.fromisoformat(utc_str.replace('Z', '+00:00'))
        return (dt + timedelta(hours=8)).isoformat()
    except: return None

def parse_num(val):
    if not val: return 0
    s = str(val).replace(',', '').replace('$', '').replace('%', '')
    try: return float(s)
    except: return 0

def process(raw_data, path):
    processed_list = []
    engine_type = "sniper" if "sniper" in path.lower() else "radar"
    if isinstance(raw_data, dict) and "items" in raw_data: items = raw_data["items"]
    elif isinstance(raw_data, list): items = raw_data
    else: items = [raw_data]

    # 1. å¤‡ç”¨æ—¶é—´ï¼ˆä»…å½“ JSON é‡Œæ²¡æ—¶é—´æ—¶ä½¿ç”¨ï¼‰
    force_now_time = (datetime.utcnow() + timedelta(hours=8)).isoformat()
    
   for item in items:
        # ğŸ”¥ 2. æ ¸å¿ƒä¿®æ”¹ï¼šä¼˜å…ˆå°è¯•è·å–åŸå§‹æ•°æ®çš„æ›´æ–°æ—¶é—´
        # Polymarket åŸå§‹ JSON é€šå¸¸å¸¦æœ‰ updatedAt å­—æ®µ
        raw_time = item.get('updatedAt') 
        bj_time_final = to_bj_time(raw_time) if raw_time else force_now_time
        
        entry = {
            "bj_time": bj_time_final, # âœ… ç°åœ¨å®ƒæ˜¯çœŸå®çš„æˆ–è€…æ˜¯å½“æ—¶å…¥åº“çš„æ—¶é—´
            "title": item.get('eventTitle'),
            "slug": item.get('slug'),
            "ticker": item.get('ticker'),
            "question": item.get('question'),
            "prices": str(item.get('prices')),
            "category": item.get('category', 'OTHER'),
            "volume": parse_num(item.get('volume')),
            "liquidity": parse_num(item.get('liquidity')),
            "vol24h": parse_num(item.get('vol24h')),
            "day_change": parse_num(item.get('dayChange')),
            "engine": engine_type,
            "strategy_tags": item.get('strategy_tags', []),
            "raw_json": item
        }
        processed_list.append(entry)
    return processed_list

def calculate_score(item):
    vol24h = float(item.get('vol24h') or 0)
    day_change = abs(float(item.get('dayChange') or item.get('day_change') or 0))
    score = vol24h * (day_change + 1)
    text = (str(item.get('title')) + " " + str(item.get('question'))).lower()
    snipers = ["gold", "bitcoin", "btc", "fed", "federal reserve", "xau"]
    if any(k in text for k in snipers) and "warsh" not in text: score *= 100
    tags = item.get('strategy_tags') or []
    if 'TAIL_RISK' in tags: score *= 50
    return score

# ğŸ”¥ ä¿®å¤ f-string æŠ¥é”™
def get_win_rate_str(price_str):
    try:
        if "Yes:" in price_str: 
            val = float(price_str.split('Yes:')[1].split('%')[0])
            return f"Yes {val:.0f}%"
        if "Up:" in price_str: 
            val = float(price_str.split('Up:')[1].split('%')[0])
            return f"Up {val:.0f}%"
        if "{" in price_str:
            clean_json = price_str.replace("'", '"')
            val = float(json.loads(clean_json)) * 100
            return f"{val:.0f}%"
    except: pass
    return str(price_str)[:15]

def get_hot_items(supabase, table_name):
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_data = res.data if res.data else []
    except Exception as e: return {}
    if not all_data: return {}

    # ğŸ”¥ 1. å¿«ç…§å»é‡ï¼šåªç•™æœ€æ–°æ—¶é—´æˆ³
    def deduplicate_snapshots(items):
        latest_map = {}
        for item in items:
            unique_key = f"{item['slug']}_{item['question']}"
            if unique_key not in latest_map:
                latest_map[unique_key] = item
            else:
                if item.get('bj_time', '0') > latest_map[unique_key].get('bj_time', '0'):
                    latest_map[unique_key] = item
        return list(latest_map.values())

    clean_data = deduplicate_snapshots(all_data)
    
    sniper_pool = [i for i in clean_data if i.get('engine') == 'sniper']
    radar_pool = [i for i in clean_data if i.get('engine') == 'radar']
    sector_matrix = {}
    global_seen_slugs = set()

    def anti_flood_filter(items):
        grouped = {}
        for i in items:
            s = i['slug']
            if s not in grouped: grouped[s] = []
            grouped[s].append(i)
        final = []
        for s, rows in grouped.items():
            for r in rows: r['_temp_score'] = calculate_score(r)
            rows.sort(key=lambda x: x['_temp_score'], reverse=True)
            final.extend(rows[:2])
        return final

    # ğŸ”¥ 2. æ„å»º 8 åˆ—å®½è¡¨
    def build_markdown(items):
        # è¡¨å¤´ä¿æŒä¸å˜
        header = "| ä¿¡å· | æ ‡é¢˜ | é—®é¢˜ | Prices (Yes/No) | Vol | Liq | 24h | Tags |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |"
        rows = []
        for i in items:
            # 1. ä¿¡å·ä¿æŒä¸å˜
            signal = fmt_k(i['_temp_score'])
            
            # 2. ä¿®æ”¹æ ‡é¢˜é€»è¾‘ï¼šæ”¾å®½é™åˆ¶åˆ° 60 å­—ç¬¦ï¼Œé˜²æ­¢å¤ªçŸ­çœ‹ä¸æ¸…
            # åŒæ—¶ç§»é™¤æ¢è¡Œç¬¦ï¼Œé˜²æ­¢ç ´åè¡¨æ ¼æ ¼å¼
            raw_title = str(i.get('title', '-')).replace('|', '').replace('\n', ' ')
            title = raw_title[:60] + ('...' if len(raw_title) > 60 else '')
            
            # 3. é—®é¢˜é“¾æ¥ä¿æŒä¸å˜ï¼Œç¨å¾®æ”¾å®½é•¿åº¦
            q_text = str(i.get('question', '-')).replace('|', '').replace('\n', ' ')
            q_text_short = q_text[:50] + "..." # ç¨å¾®åŠ é•¿ä¸€ç‚¹
            question = f"[{q_text_short}](https://polymarket.com/event/{i['slug']})"
            
            # 4. ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šä»·æ ¼æ˜¾ç¤º
            # å‡è®¾ i['prices'] æ˜¯ç±»ä¼¼ "Yes: 0.5% | No: 99.5%" çš„å­—ç¬¦ä¸²
            # å¿…é¡»æŠŠä¸­é—´çš„ '|' æ›¿æ¢æ‰ï¼Œå¦åˆ™ Markdown è¡¨æ ¼ä¼šå´©å
            # æ–¹æ¡ˆ A: ç”¨æ–œæ  (Yes: 0.5% / No: 99.5%)
            raw_prices = str(i.get('prices', 'N/A'))
            prices = raw_prices.replace('|', '/') 
            
            # æ–¹æ¡ˆ B (å¯é€‰): å¦‚æœæ”¯æŒ HTMLï¼Œå¯ä»¥ç”¨ <br> æ¢è¡Œæ˜¾ç¤ºæ›´æ¸…æ™°
            # prices = raw_prices.replace('|', '<br>') 

            # å…¶ä»–æ•°å€¼ä¿æŒä¸å˜
            vol = fmt_k(i.get('volume', 0), '$')
            liq = fmt_k(i.get('liquidity', 0), '$')
            v24 = fmt_k(i.get('vol24h', 0), '$')
            tags = ", ".join(i.get('strategy_tags', []))[:20] # Tags ä¹Ÿç¨å¾®æ”¾å®½ä¸€ç‚¹

            row = f"| **{signal}** | {title} | {question} | {prices} | {vol} | {liq} | {v24} | {tags} |"
            rows.append(row)
            
            # è®°å½• slug (ä¿æŒåŸé€»è¾‘)
            if 'slug' in i:
                global_seen_slugs.add(i['slug'])
                
        return {"header": header, "rows": rows}

    if sniper_pool:
        refined = anti_flood_filter(sniper_pool)
        refined.sort(key=lambda x: x['_temp_score'], reverse=True)
        sector_matrix["ğŸ¯ SNIPER (æ ¸å¿ƒç›‘æ§)"] = build_markdown(refined)

    # ğŸ”¥ 3. é¡ºåºï¼šæ”¿æ²»å‹è½´
    SECTORS_LIST = [
        "Geopolitics", "Science", "Climate-Science", "Tech", 
        "Finance", "Crypto", "Economy", "Politics"
    ]
    
    MAP = {
        'POLITICS': 'Politics', 'GEOPOLITICS': 'Geopolitics', 'TECH': 'Tech', 
        'FINANCE': 'Finance', 'CRYPTO': 'Crypto', 'SCIENCE': 'Science', 
        'ECONOMY': 'Economy', 'BUSINESS': 'Economy',
        'CLIMATE': 'Climate-Science', 'GLOBAL WARMING': 'Climate-Science', 'ENVIRONMENT': 'Climate-Science'
    }

    if radar_pool:
        for s in SECTORS_LIST:
            pool = [
                i for i in radar_pool 
                if (MAP.get(i.get('category'), 'Other') == s or i.get('category') == s.upper())
                and i['slug'] not in global_seen_slugs
            ]
            if not pool: continue
            refined = anti_flood_filter(pool)
            refined.sort(key=lambda x: x['_temp_score'], reverse=True)
            quota = max(3, math.ceil((len(pool) / len(radar_pool)) * RADAR_TARGET_TOTAL))
            sector_matrix[s] = build_markdown(refined[:quota])

    return sector_matrix
